{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-10T03:36:30.031579Z",
     "start_time": "2025-07-10T03:36:22.264343Z"
    }
   },
   "source": [
    "from rag.vector_base import VectorStore\n",
    "from rag.utils import ReadFiles\n",
    "from rag.embeddings import BgeEmbedding\n",
    "from rag.llm import GeminiChat"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 构建向量数据库",
   "id": "395e3d837633f9e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T03:48:27.109571Z",
     "start_time": "2025-07-10T03:48:24.792588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reader = ReadFiles('../data/1')\n",
    "docs = reader.get_content(max_token_len=1024, cover_content=256)\n",
    "len(docs)"
   ],
   "id": "469f9bc5bc19f67d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T04:13:04.977355Z",
     "start_time": "2025-07-10T03:48:34.858466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding = BgeEmbedding(device='mps')\n",
    "vector_store = VectorStore(docs)\n",
    "vectors = vector_store.get_vector(embedding)\n",
    "vector_store.persist(file='d2l')"
   ],
   "id": "e13394c4e58e4b29",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 1682/1682 [24:24<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 加载向量数据库并测试",
   "id": "92b30932a754aa35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T05:12:25.281072Z",
     "start_time": "2025-07-10T05:12:17.278880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector_store = VectorStore()\n",
    "vector_store.load_vector(file='d2l')\n",
    "embedding = BgeEmbedding(device='mps')\n",
    "question = '缩放点积注意力的原理？'\n",
    "content = vector_store.query(question, EmbeddingModel=embedding, k=1)[0]\n",
    "content"
   ],
   "id": "ee958743339a5c2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'是独立的随机变量，\\n并且都满足零均值和单位方差，\\n那么两个向量的点积的均值为$0$，方差为$d$。\\n为确保无论向量长度如何，\\n点积的方差在不考虑向量长度的情况下仍然是$1$，\\n我们再将点积除以$\\\\sqrt{d}$，\\n则缩放点积注意力（scaled dot-product attention）评分函数为：\\n$$a(\\\\mathbf q, \\\\mathbf k) = \\\\mathbf{q}^\\\\top \\\\mathbf{k}  /\\\\sqrt{d}.$$\\n在实践中，我们通常从小批量的角度来考虑提高效率，\\n例如基于$n$个查询和$m$个键－值对计算注意力，\\n其中查询和键的长度为$d$，值的长度为$v$。\\n查询$\\\\mathbf Q\\\\in\\\\mathbb R^{n\\\\times d}$、\\n键$\\\\mathbf K\\\\in\\\\mathbb R^{m\\\\times d}$和\\n值$\\\\mathbf V\\\\in\\\\mathbb R^{m\\\\times v}$的缩放点积注意力是：\\n$$ \\\\mathrm{softmax}\\\\left(\\\\frac{\\\\mathbf Q \\\\mathbf K^\\\\top }{\\\\sqrt{d}}\\\\right) \\\\mathbf V \\\\in \\\\mathbb{R}^{n\\\\times v}.$$\\n:eqlabel:eq_softmax_QK_V\\n下面的缩放点积注意力的实现使用了暂退法进行模型正则化。\\n```{.python .input}\\n@save\\nclass DotProductAttention(nn.Block):\\n    \"\"\"缩放点积注意力\"\"\"\\n    def init(self, dropout, kwargs):\\n        super(DotProductAttention, self).init(kwargs)\\n        self.dropout = nn.Dropout(dropout)\\n# queries的形状：(batch_size，查询的个数，d)\\n# keys的形状：(batch_size，“键－值”对的个数，d)\\n# values的形状：(batch_size，“键－值”对的个数，值的维度)\\n# valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\\ndef forward(self, queries, keys, values, valid_lens=None):\\n    d = queries.shape[-1]\\n    # 设置transpose_b=True为了交换keys的最后两个维度\\n    scores = npx.batch_dot(queries, keys, transpose_b=True) / math.sqrt(d)\\n    self.attention_weights = masked_softmax(scores, valid_lens)\\n    return npx.batch_dot(self.dropout(self.attention_weights), values)\\n\\n```\\n```{.python .input}\\n@tab pytorch\\n@save\\nclass DotProductAttention(nn.Module):\\n    \"\"\"缩放点积注意力\"\"\"\\n    def init(self, dropout, kwargs):\\n        super(DotProductAttention, self).init(kwargs)\\n        self.dropout = nn.Dropout(dropout)\\n# queries的形状：(batch_size，查询的个数，d)\\n# keys的形状：(batch_size，“键－值”对的个数，d)\\n# values的形状：(batch_size，“键－值”对的个数，值的维度)\\n# valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\\ndef forward(self, queries, keys, values, valid_lens=None):\\n    d = queries.shape[-1]\\n    # 设置transpose_b=True为了交换keys的最后两个维度\\n    scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\\n    self.attention_weights = masked_softmax(scores, valid_lens)\\n    return torch.bmm(self.dropout(self.attention_weights), values)\\n\\n```\\n```{.python .input}\\n@tab tensorflow\\n@save\\nclass DotProductAttention(tf.keras.layers.Layer):\\n    \"\"\"Scaleddotproductattention.\"\"\"\\n    def init(self, dropout, kwargs):\\n        super().init(kwargs)\\n        self.dropout = tf.keras.layers.Dropout(dropout)\\n# queries的形状：(batch_size，查询的个数，d)\\n# keys的形状：(batch_size，“键－值”对的个数，d)\\n# values的形状：(batch_size，“键－值”对的个数，值的维度)\\n# valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\\ndef call(self, queries, keys, values, valid_lens, **kwargs):\\n    d ='"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T05:12:36.483426Z",
     "start_time": "2025-07-10T05:12:32.970538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat = GeminiChat(model='gemini-2.5-flash')\n",
    "res = chat.chat(question, [], content)\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(res))"
   ],
   "id": "c98190f76abbc7ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "缩放点积注意力的原理如下：\n\n为了确保点积的方差在不考虑向量长度的情况下仍然是$1$，无论向量长度如何，我们会将查询向量$\\mathbf q$和键向量$\\mathbf k$的点积$\\mathbf{q}^\\top \\mathbf{k}$除以$\\sqrt{d}$，其中$d$是向量的维度（长度）。\n\n因此，缩放点积注意力（scaled dot-product attention）的评分函数为：\n$$a(\\mathbf q, \\mathbf k) = \\mathbf{q}^\\top \\mathbf{k} /\\sqrt{d}.$$\n\n在实际应用中，当处理批量数据时，对于查询矩阵$\\mathbf Q$、键矩阵$\\mathbf K$和值矩阵$\\mathbf V$，缩放点积注意力计算为：\n$$ \\mathrm{softmax}\\left(\\frac{\\mathbf Q \\mathbf K^\\top }{\\sqrt{d}}\\right) \\mathbf V $$\n这里，$\\mathbf Q \\mathbf K^\\top$计算了所有查询和键之间的点积，然后通过除以$\\sqrt{d}$进行缩放，接着应用softmax函数得到注意力权重，最后将这些权重与值矩阵$\\mathbf V$相乘。"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 召回的RAG",
   "id": "349a027b2ded00cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T04:16:18.021620Z",
     "start_time": "2025-07-10T04:16:05.727016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.reranker import BgeReranker\n",
    "\n",
    "reranker = BgeReranker()\n",
    "vector_store = VectorStore()\n",
    "vector_store.load_vector(file='stochastic_process')\n",
    "\n",
    "question = '残差连接是什么？'\n",
    "# 从向量数据库中查询出最相似的3个文档\n",
    "content = vector_store.query(question, EmbeddingModel=embedding, k=3)\n",
    "# 从一阶段查询结果中用Reranker再次筛选出最相似的2个文档\n",
    "rerank_content = reranker.rerank(question, content, k=2)\n",
    "# 最后选择最相似的文档, 交给LLM作为可参考上下文\n",
    "best_content = rerank_content[0]\n",
    "\n",
    "chat = GeminiChat(model='gemini-2.5-flash')\n",
    "res = chat.chat(question, [], best_content)\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(res))\n"
   ],
   "id": "7c639a7f2b90b09e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "残差连接是残差网络（ResNet）中残差块的核心组成部分。它的主要思想是，不是直接学习一个理想映射 $f(\\mathbf{x})$，而是学习一个残差映射 $f(\\mathbf{x}) - \\mathbf{x}$。\n\n在残差块中，原始输入 $\\mathbf{x}$ 会被“连接”到（通常是通过跳跃连接或快捷连接）经过一些层处理后的输出上。具体来说，如果中间层学习到了残差映射 $f(\\mathbf{x}) - \\mathbf{x}$，那么最终的输出就是这个残差映射加上原始输入 $\\mathbf{x}$，即 $(f(\\mathbf{x}) - \\mathbf{x}) + \\mathbf{x} = f(\\mathbf{x})$。\n\n这种设计使得网络更容易优化。尤其当理想映射 $f(\\mathbf{x})$ 接近于恒等映射 $f(\\mathbf{x}) = \\mathbf{x}$ 时，残差映射 $f(\\mathbf{x}) - \\mathbf{x}$ 就会接近于零，网络只需要学习微小的波动。这有助于解决深度神经网络中层数增加时难以训练的问题，并确保新模型至少可以达到原有模型的性能（通过将新增层的权重和偏置设为0，使其学习恒等映射）。"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T04:16:54.645846Z",
     "start_time": "2025-07-10T04:16:54.641172Z"
    }
   },
   "cell_type": "code",
   "source": "embedding._model",
   "id": "99c7cec88ee6bec4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): XLMRobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "    (position_embeddings): Embedding(8194, 1024, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): XLMRobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): XLMRobertaPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T04:19:37.348297Z",
     "start_time": "2025-07-10T04:19:37.340913Z"
    }
   },
   "cell_type": "code",
   "source": "reranker._model",
   "id": "c806c31e0c232ec2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
